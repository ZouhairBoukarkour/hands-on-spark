version: "2"
 
services:
  namenode:
    image: uhopper/hadoop-namenode
    hostname: namenode
    container_name: namenode
    environment:
      - CLUSTER_NAME="hadoopy"
    ports:
    - 50070:9090
    links:
      - spark
      - resourcemanager
      - nodemanager1
      - datanode1
      
  datanode1:
    image: uhopper/hadoop-datanode
    hostname: datanode1
    container_name: datanode1  
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020

  resourcemanager:
    image: uhopper/hadoop-resourcemanager
    hostname: resourcemanager
    container_name: resourcemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_log___aggregation___enable=true
    ports:
      - 8088:8088

  nodemanager1:
    image: uhopper/hadoop-nodemanager
    hostname: nodemanager1
    container_name: nodemanager1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemananger
      - YARN_CONF_yarn_log___aggregation___enable=true
      - YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs

  spark:
    image: uhopper/hadoop-spark
    hostname: spark
    container_name: spark  
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    ports:
      - 4040:4040
      - 4041:4041
      - 4042:4042
    volumes:
      - ~/Workspaces/hands-on-spark/:/root/
    command: tail -f /var/log/dmesg
